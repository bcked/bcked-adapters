name: Crawler Execution

on:
    schedule:
        # Runs "At minute 0 (every hour)." (see https://crontab.guru)
        - cron: "0 * * * *"
    workflow_dispatch:

# Allow one concurrent deployment
concurrency:
    group: "crawler"
    cancel-in-progress: true

jobs:
    crawler:
        runs-on: ubuntu-latest
        name: Crawler Execution
        steps:
            - name: Checkout
              uses: actions/checkout@v3
              with:
                  ref: records
            - name: Use Node.js
              uses: actions/setup-node@v3
              with:
                  node-version: "20.x"
                  cache: "npm"
            - name: Install Dependencies
              run: npm ci
            - name: Execute Job
              env:
                  ALCHEMY_ETHEREUM: ${{ secrets.ALCHEMY_ETHEREUM }}
                  ALCHEMY_POLYGON: ${{ secrets.ALCHEMY_POLYGON }}
                  ALCHEMY_SOLANA: ${{ secrets.ALCHEMY_SOLANA }}
                  ALCHEMY_ARBITRUM: ${{ secrets.ALCHEMY_ARBITRUM }}
                  ETHERSCAN_API_KEY: ${{ secrets.ETHERSCAN_API_KEY }}
                  BCKED_WATCHER_BOT_TOKEN: ${{ secrets.BCKED_WATCHER_BOT_TOKEN }}
              run: node ./src/crawler/job.js
            - name: Commit Results on records Branch
              uses: stefanzweifel/git-auto-commit-action@v4
              with:
                  commit_message: Update data
                  commit_user_name: GitHub Action
                  commit_user_email: action@github.com
                  commit_author: actions-user <action@github.com>
                  file_pattern: "*.csv *.json"
